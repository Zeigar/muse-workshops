{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NT@B Software Workshop 1\n",
    "### Data Acquisition & Cleaning\n",
    "#### Saarang Panchavati and Abhinav Pottabathula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Jupyter \n",
    "Welcome to Jupyter Notebook! Let's get you familiarized with Jupyter. If you're already familiar with the Jupyter environment you can move on to the next section.\n",
    "\n",
    "Jupyter is really cool because you can execute your code in _cells_ instead of all at once. This is extremely useful for data science because you can iterate through different methods of analysis without having to run all your code at once. \n",
    "\n",
    "By default, you are in *command* mode in command mode, you can do the following:\n",
    "1. Change a cells _type_: (code, markdown or raw). The type of this cell is markdown, where you can write stuff and make it look pretty\n",
    "2. Add and Delete Cells\n",
    "3. Run Cells\n",
    "\n",
    "To re-enter *command* mode, just press `esc` on your keyboard.\n",
    "\n",
    "Here are the most useful keyboard shortcuts:\n",
    "1. `shift + enter` runs a cell\n",
    "2. `a`,`b` adds a cell above and below the current one, respectively\n",
    "3. `y` changes a cell to code type\n",
    "4. `m` changes as cell to markdown type\n",
    "5. `d+d` deletes the selected cell\n",
    "6. `z+z` is undo\n",
    "7. `i+i` interrupts the notebook (in case you have an infinite loop or something)\n",
    "\n",
    " \n",
    "\n",
    "Some things to remember:\n",
    "1. The number next to a cell is the order in which it was run, if there's a star there then that means it is still running. \n",
    "2. Jupyter saves variables even if you delete the cell, so if you want to re-run your notebook or run a cell, make sure you're aware of what the variables are set to!\n",
    "3. Be sure to stay organized in your notebook â€” it can become very hard to find cells or portions of your code if you don't organize your code in a nice way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert this cell in to code type and run it with shift enter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a0998ca58441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#interrupt with ii, interrupt quickly or this might break your laptop lol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#interrupt with ii, interrupt quickly or this might break your laptop lol\n",
    "while True:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Pandas! \n",
    "\n",
    "__Pandas is THE library for datascience! It is really important to be familiar with it and understand how to use it. Let's dive in!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded \n",
    "    \n",
    "    return: The pathlib.Path to the file.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        import time \n",
    "        created = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using cached version downloaded at\", created)\n",
    "    return file_path\n",
    "\n",
    "data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip')\n",
    "zf = zipfile.ZipFile(namesbystate_path, 'r')\n",
    "\n",
    "column_labels = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "def load_dataframe_from_zip(zf, f):\n",
    "    with zf.open(f) as fh: \n",
    "        return pd.read_csv(fh, header=None, names=column_labels)\n",
    "\n",
    "states = [\n",
    "    load_dataframe_from_zip(zf, f)\n",
    "    for f in sorted(zf.filelist, key=lambda x:x.filename) \n",
    "    if f.filename.endswith('.TXT')\n",
    "]\n",
    "\n",
    "baby_names = states[0]\n",
    "for state_df in states[1:]:\n",
    "    baby_names = pd.concat([baby_names, state_df])\n",
    "baby_names = baby_names.reset_index().iloc[:, 1:]\n",
    "ca = baby_names[baby_names['State'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregration (Grouping Data Frames)\n",
    "\n",
    "### Question 1a\n",
    "To count the number of instances of each unique value in a `Series`, we can use the `value_counts()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) as `df[\"col_name\"].value_counts()`. Count the number of different names for each Year in `CA` (California).  (You may use the `ca` DataFrame created above.)\n",
    "\n",
    "**Note:** *We are not computing the number of babies but instead the number of names (rows in the table) for each year.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_names_per_year = ...\n",
    "num_of_names_per_year[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1b\n",
    "Count the number of different names for each gender in `CA`.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_names_per_gender = ...\n",
    "num_of_names_per_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Groupby ###\n",
    "\n",
    "Before we jump into using the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function in Pandas, let's recap how grouping works in general for tabular data through a guided set of questions based on a small toy dataset of movies and genres. \n",
    "\n",
    "**Note:** If you want to see a visual of how grouping of data works, here is a link to an animation [Groupby Animation](http://www.ds100.org/sp18/assets/lectures/lec03/03-groupby_and_pivot.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Setting:** This summer 2018, there were a lot of good and bad movies that came out. Below is a dataframe with 5 columns: name of the movie as a `string`, the genre of the movie as a `string`, the first name of the director of the movie as a `string`, the average rating out of 10 on Rotten Tomatoes as an `integer`, and the total gross revenue made by the movie as an `integer`. The point of these guided questions (parts a and b) below is to understand how grouping of data works in general, **not** how grouping works in code. We will worry about how grouping works in Pandas in 7c, which will follow.\n",
    "\n",
    "Below is the `movies` dataframe we are using, imported from the `movies.csv` file located in the `lab02` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movies.csv\")\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a\n",
    "\n",
    "If we grouped the `movies` dataframe above by `genre`, how many groups would be in the output and what would be the groups? Assign `num_groups` to the number of groups created (hard-code) and fill in `genre_list` as a list containing the names of genres as strings that represent the groups.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups = ...\n",
    "genre_list = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2b\n",
    "\n",
    "Whenever we group tabular data, it is usually the case that we need to aggregate values from the ungrouped column(s). If we were to group the `movies` dataframe above by `genre`, which column(s) in the `movies` dataframe would it make sense to aggregate if we were interested in finding how well each genre did in the eyes of people? Fill in `agg_cols` with the column name(s).\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cols = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see groupby in action, instead of keeping everything abstract. To aggregate data in Pandas, we use the .groupby() function. The code below will group the movies dataframe by genre and find the average revenue and rating for each genre. You can verify you had the same number of groups as what you answered in 7a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:, ['genre', 'rating', 'revenue']].groupby('genre').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c\n",
    "\n",
    "Let's move back to baby names and specifically, the `ca` dataframe. Find the sum of `Count` for each `Name` in the `ca` table. You should use `df.groupby(\"col_name\").sum()`. Your result should be a Pandas Series.\n",
    "\n",
    "**Note:** *In this question we are now computing the number of registered babies with a given name.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2c\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_for_names = ...\n",
    "count_for_names.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2d\n",
    "\n",
    "Find the sum of `Count` for each female name after year 1999 (`>1999`) in California.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2d\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_name_count = ...\n",
    "female_name_count.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Grouping Multiple Columns\n",
    "\n",
    "Let's move back to the `movies` dataframe. Which of the following lines of code will output the following dataframe? Write your answer (hard-coded) as either 1, 2, 3, or 4. Recall that the arguments to `pd.pivot_table` are as follows: `data` is the input dataframe, `index` includes the values we use as rows, `columns` are the columns of the pivot table, `values` are the values in the pivot table, and `aggfunc` is the aggregation function that we use to aggregate `values`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>rating</th>\n",
    "      <th>5</th>\n",
    "      <th>6</th>\n",
    "      <th>7</th>\n",
    "      <th>8</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>genre</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Action &amp; Adventure</th>\n",
    "      <td>208681866.0</td>\n",
    "      <td>129228350.0</td>\n",
    "      <td>318344544.0</td>\n",
    "      <td>6708147.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Animation</th>\n",
    "      <td>374408165.0</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Comedy</th>\n",
    "      <td>55383976.0</td>\n",
    "      <td>30561590.0</td>\n",
    "      <td>NaN</td>\n",
    "      <td>111705055.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Drama</th>\n",
    "      <td>NaN</td>\n",
    "      <td>17146165.5</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Horror</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>68765655.0</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Science Fiction &amp; Fantasy</th>\n",
    "      <td>NaN</td>\n",
    "      <td>312674899.0</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) `pd.pivot_table(data=movies, index='genre', columns='rating', values='revenue', aggfunc=np.mean)`\n",
    "\n",
    "2) `movies.groupby(['genre', 'rating'])['revenue'].mean()`\n",
    "\n",
    "3) `pd.pivot_table(data=movies, index='rating', columns='genre', values='revenue', aggfunc=np.mean)`\n",
    "\n",
    "4) `movies.groupby('revenue')[['genre', 'rating']].mean()`\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_answer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4a\n",
    "\n",
    "Time to put everything together! Merge `movies` and `count_for_names` to find the number of registered baby names for each director using [`pd.merge`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html?highlight=merge#pandas.merge). Only include names that appear in both `movies` and `count_for_names`.\n",
    "\n",
    "**Hint:** You might need to convert the `count_for_names` series to a dataframe. Take a look at the ``to_frame`` method of a series to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first row should look something like this:\n",
    "\n",
    "**Note**: It is ok if you have 2 separate columns with names instead of just one column.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>director</th>\n",
    "      <th>genre</th>\n",
    "      <th>movie</th>\n",
    "      <th>rating</th>\n",
    "      <th>revenue</th>\n",
    "      <th>Count</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>David</td>\n",
    "      <td>Action &amp; Adventure</td>\n",
    "      <td>Deadpool 2</td>\n",
    "      <td>7</td>\n",
    "      <td>318344544</td>\n",
    "      <td>371646</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</table>\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = ...\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4b\n",
    "\n",
    "How many directors in the original `movies` table did not get included in the `merged_df` dataframe? Please hard-code your answer as a number in `q4b`, then explain your answer in 1-2 sentences as a comment below.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_4b = ...\n",
    "\n",
    "# Explain your solution: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's use EEG Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first part of a larger project we will be putting together in the next few weeks! We have chosen the [EEG-Alcohol](https://www.kaggle.com/nnair25/Alcoholics) dataset, which contains [EEG (Electroencephalography)](https://en.wikipedia.org/wiki/Electroencephalography) data for two groups - Alcoholic and Control Group. \n",
    "![](https://i.imgur.com/ZrmxJRu.jpg)\n",
    "There are 8 subjects in each group. The 64 electrodes were placed on subject's scalps to measure the electrical activity of the brain. The response values were sampled at 256 Hz (3.9-msec epoch) for 1 second. Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the [1980 Snodgrass and Vanderwart picture set](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.1979&rep=rep1&type=pdf). When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2.\n",
    "\n",
    "The purpose of our analysis is going to be to find out if there is a difference in response values for different stimuli between control and alcoholic group. And if so, in what brain regions this happens? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some more imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "init_notebook_mode(connected=True) ## plotly init\n",
    "seed = 123\n",
    "random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total amount of files in SMNI_CMI_TRAIN directory: ' + str(len(os.listdir('../input/SMNI_CMI_TRAIN/'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/SMNI_CMI_TRAIN/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7ac57bd1ff20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilenames_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/SMNI_CMI_TRAIN/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## list of file names in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEEG_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## create an empty df that will hold data from each file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/SMNI_CMI_TRAIN/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## read from the file to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/SMNI_CMI_TRAIN/'"
     ]
    }
   ],
   "source": [
    "filenames_list = os.listdir('../input/SMNI_CMI_TRAIN/') ## list of file names in the directory\n",
    "EEG_data = pd.DataFrame({}) ## create an empty df that will hold data from each file\n",
    "\n",
    "for file_name in tqdm(filenames_list):\n",
    "    temp_df = pd.read_csv('../input/SMNI_CMI_TRAIN/' + file_name) ## read from the file to df\n",
    "    EEG_data = EEG_data.append(temp_df) ## add the file data to the main df\n",
    "    \n",
    "EEG_data = EEG_data.drop(['Unnamed: 0'], axis=1) ## remove the unused column\n",
    "EEG_data.loc[EEG_data['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EEG_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b2155f94f3e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## here is how the data looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mEEG_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EEG_data' is not defined"
     ]
    }
   ],
   "source": [
    "## here is how the data looks like\n",
    "EEG_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='var_des'>2.2. Variables description</a>\n",
    "\n",
    "* `trial number`: number of the trial (obviously) \n",
    "* `sensor postition`:  position of electrode placed on subject's scalp (based on International 10-20 system)\n",
    "<img src=\"https://i.ibb.co/M2GRQNz/670px-International-10-20-system-for-EEG-MCN-svg.png\" alt=\"670px-International-10-20-system-for-EEG-MCN-svg\" border=\"0\">\n",
    "* `sample num`: 0-255\n",
    "* `sensor value`: value in microvolts \n",
    "* `subject identifier`: `a` - Alcoholic; `c` - Control\n",
    "* `matching condition`: \n",
    " * `S1 obj` - a single object shown; \n",
    " * `S2 match` - object 2 shown in a matching condition (S1 was identical to S2), \n",
    " * `S2 nomatch` - object 2 shown in a non matching condition (S1 differed from S2)\n",
    "* `channel`: channel number (0-63). Basically, it's the same as `sensor position` column, so one of these columns can be dropped\n",
    "* `name`: a serial code assigned to each subject\n",
    "* `time`: inverse of `sample num` measured in seconds\n",
    "\n",
    "\n",
    "I have changed some `sensor position`s so they match the basics for head topography visualization. Also, I have removed those positions which equal to **X**, **Y** and **ND** since I couldnt figure out which regions they respond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EEG_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5479e0953abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## replace some 'sensor position' values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mEEG_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEEG_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AF1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AF3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mEEG_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEEG_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AF2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AF4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEEG_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEEG_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PO1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PO3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEEG_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEEG_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PO2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PO4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EEG_data' is not defined"
     ]
    }
   ],
   "source": [
    "## replace some 'sensor position' values\n",
    "EEG_data.loc[EEG_data['sensor position'] == 'AF1', 'sensor position'] = 'AF3'\n",
    "EEG_data.loc[EEG_data['sensor position'] == 'AF2', 'sensor position'] = 'AF4'\n",
    "EEG_data.loc[EEG_data['sensor position'] == 'PO1', 'sensor position'] = 'PO3'\n",
    "EEG_data.loc[EEG_data['sensor position'] == 'PO2', 'sensor position'] = 'PO4'\n",
    "## remove rows with undefined positions\n",
    "EEG_data = EEG_data[(EEG_data['sensor position'] != 'X') & (EEG_data['sensor position'] != 'Y') & (EEG_data['sensor position'] != 'nd')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Practice\n",
    "\n",
    "The best way to learn how to clean data is by doing a bunch of practice!\n",
    "\n",
    "- Click [this](https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb) link and complete the quick tutorial.\n",
    "\n",
    "- Check out this publicly available dataset and figure out how to parse it! Go to http://www.mindbigdata.com/opendb/  and download the MindBigData-MU-v1.0.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
